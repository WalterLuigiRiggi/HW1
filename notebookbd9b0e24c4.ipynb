{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **HOMEWORK 1 - Regressione Lineare**\n\nIn questo homework dovrete:\n\n1. Scrivere una funzione di pipeline che deve gestire l' allenamento di un modello di regressione lineare al variare degli iperparametri forniti. Nello specifico:\n    * Deve applicare la PCA, se presente.\n    \n    * Deve applicare la standardizzazione, se presente.\n\n    * Deve applicare la regolarizzazione, se presente.\n\n    * Deve allenare il modello di regressione lineare.\n\n    * Deve calcolare la MAE.\n\n2. Scrivere una funzione che utilizzi la `pipeline` definita al punto 1 e che testi tutte le configurazioni possibili presenti in `configuration`. Nel dettaglio la funzione deve:\n    * Dividere il dataset in tr e vidation.\n\n    * Calcolare, grazie alla funzione `pipeline` definita al punto 1, quale configurazione ottiene il punteggio migliore (quale configurazione ha la MAE di vidation più bassa).\n\n3. Scrivere una funzione che utilizzi la configurazione migliore prodotta dalla funzione definita al punto 2 e la testi sul test set. \n\n4. Stampare:\n    * La migliore configurazione\n\n    * Il miglior MAE di vidation \n\n    * Il migliore MAE di tr\n\n    * Il MAE di test \n\n\nIl codice che di seguito trovate già fornito deve essere utilizzato per la risoluzione dell' homework, **NON MODIFICATELO IN ALCUN MODO**.","metadata":{}},{"cell_type":"markdown","source":"## **Dataset Wine Quality White**\n\nIl dataset da utilizzare è `wine-quality-white` della libreria `scikit-learn`. Il dataset contiene 11 variabili numeriche + 1 di target che classifica il vino in diverse categorie di qualità. Per il nostro obiettivo la variabile di target è considerata come `float`, permettendoci di applicare la regressione lineare. All' interno del dataset sono contenuti 4898 campioni. ","metadata":{}},{"cell_type":"code","source":"# Questa cella contiene tutte le librerie di cui necessitate per risolvere l' homework.\n# Ricordate di eseguirla prima di iniziare.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:21:50.552810Z","iopub.execute_input":"2025-04-24T17:21:50.553125Z","iopub.status.idle":"2025-04-24T17:21:50.558000Z","shell.execute_reply.started":"2025-04-24T17:21:50.553102Z","shell.execute_reply":"2025-04-24T17:21:50.557075Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"hyperparams = {\n    # PCA\n    'use_pca': [True, False],\n    'pca_standardize': [True, False],\n    'pca_components': [3, 5, 10],\n    # Data standardization\n    'data_standardize': [True, False],\n    # Regularization l2\n    'use_regularization': [True, False],\n    'reg_lambda': [0.1, 1, 10],\n}\n\n# Calcoliamo tutte le possibili combinazioni di iperparametri\nimport itertools\ncombinations = list(itertools.product(*hyperparams.values()))\nconfiguration = [dict(zip(hyperparams.keys(), combination)) for combination in combinations]\n\n# Evitiamo le combinazioni non va lide\nfor config in configuration:\n    if not config['use_pca']:\n        config['pca_standardize'] = None\n        config['pca_components'] = None\n    if not config['use_regularization']:\n        config['reg_lambda'] = None\nconfiguration = set([tuple(config.items()) for config in configuration])\n\n# Convertiamo di nuovo in lista di dizionari\nconfiguration = [dict(config) for config in configuration]\nprint(f'Numero di combinazioni: {len(configuration)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:21:52.446748Z","iopub.execute_input":"2025-04-24T17:21:52.447528Z","iopub.status.idle":"2025-04-24T17:21:52.455724Z","shell.execute_reply.started":"2025-04-24T17:21:52.447467Z","shell.execute_reply":"2025-04-24T17:21:52.454899Z"}},"outputs":[{"name":"stdout","text":"Numero di combinazioni: 56\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Carica il dataset Wine Quality White\ndata = fetch_openml(name='wine-quality-white', version=1, as_frame=True)\nX = data.data\ny = data.target.astype(float)  # Assicura che il target sia float per la regressione\n\ndef pipeline(X_tr, y_tr, X_v, y_v, hyperparams):\n    \"\"\"\n    Addestra un modello di regressione lineare con eventuale PCA e regolarizzazione L2.\n    \"\"\"\n   if hyperparams['use_pca']:\n        if hyperparams['pca_standardize']:\n            scaler_pca = StandardScaler().fit(X_tr)\n            X_tr = scaler_pca.transform(X_tr)\n            X_v = scaler_pca.transform(X_v)\n        pca = PCA(n_components=hyperparams['pca_components'])\n        X_tr = pca.fit_transform(X_tr)\n        X_v = pca.transform(X_v)\n\n    if hyperparams['data_standardize']:\n        scaler = StandardScaler().fit(X_tr)\n        X_tr = scaler.transform(X_tr)\n        X_v = scaler.transform(X_v)\n\n\n\n    # Aggiunge il termine costante ai dati\n    # ...\n\n    X_tr = np.c_[np.ones(len(X_tr)), X_tr]\n    X_v  = np.c_[np.ones(len(X_v)),  X_v]\n    \n\n    # Calcolo della soluzione di regressione lineare\n    if hyperparams['use_regularization']:\n        I = np.eye(X_tr.shape[1])\n        I[0,0] = 0\n        parametri = (np.linalg.inv(X_tr.T @ X_tr + hyperparams['reg_lambda'] * I)) @ X_tr.T @ y_tr\n    else:\n        parametri = (np.linalg.inv(X_tr.T @ X_tr)) @ X_tr.T @ y_tr\n        \n\n    # Calcolo predizioni\n    # ...\n\n    y_tr_pred = X_tr @ parametri\n    y_v_pred = X_v @ parametri\n    # Calcola il MAE\n    # ...\n\n    MAE_tr = np.mean(np.abs(y_tr - y_tr_pred))\n    MAE_v = np.mean(np.abs(y_v - y_v_pred))\n\n    return MAE_tr, MAE_v, parametri\n\n# Dividi il dataset in tring e test set\n# ...\n\nporzione_tr = 0.8\nporzione_test = 0.2\nnum_tr = int(porzione_tr * X.shape[0])\nX_tr = X[:num_tr]\ny_tr = y[:num_tr]\nX_test = X[num_tr:]\ny_test = y[num_tr:]\n\n# Dividi il training set in training set effettivo e validation set\n# ...\n\nporzione_tr_ef = 0.8\nporzione_v = 0.2\nnum_tr_ef = int(porzione_tr_ef * X_tr.shape[0])\nX_tr_ef = X_tr[:num_tr_ef]\ny_tr_ef = y_tr[:num_tr_ef]\nX_v = X_tr[num_tr_ef:]\ny_v = y_tr[num_tr_ef:]\n# Trova la configurazione di iperparametri migliore\n# ...\n\nimprove_config = None\nimprove_mae_v = float('inf')\nimprove_mae_tr = None\n   \nfor config in configuration:\n       # X_tr_ef = X_tr_ef.copy()\n       #X_v = X_v.copy() \n    mae_tr, mae_v, _ = pipeline(X_tr_ef, y_tr_ef, X_v, y_v, config)\n        \n    if mae_v < improve_mae_v:\n            \n        improve_mae_v = mae_v\n        improve_config = config\n        improve_mae_tr = mae_tr\n\n# Riallena il modello sul tring set completo\n# ...\n\n_, _, improve_parametri = pipeline(X_tr, y_tr, X_test, y_test, improve_config)\n\n# Calcola il MAE sul test set\n# ...\n\nX_test_copy = X_test.copy()\nif improve_config['use_pca']:\n    if improve_config['pca_standardize']:\n        X_tr = scaler_pca.fit_transform(X_tr)\n        X_test_copy = scaler_pca.transform(X_test_copy)\n    pca = PCA(n_components=improve_config['pca_components'])\n    X_tr = pca.fit_transform(X_tr)\n    X_test_copy = pca.transform(X_test_copy)\n    \n\nif improve_config['data_standardize']:\n    scaler = StandardScaler()\n    X_tr = scaler.fit_transform(X_tr)\n    X_test_copy = scaler.transform(X_test_copy)\n\nX_tr = np.c_[np.ones((X_tr.shape[0], 1)), X_tr]\nX_test_copy = np.c_[np.ones((X_test_copy.shape[0], 1)), X_test_copy]\n\ny_test_pred = X_test_copy @ improve_parametri\nmae_test = np.mean(np.abs(y_test - y_test_pred))\n\n# Stampa  risultati\n# ...\n\nprint(f\"La miglior combinazione degli iperparametri è: \\n{improve_config}\")\nprint(f\"Il risultato migliore del MAE calcolato sul validation set è: {improve_mae_v:.4f}\")\nprint(f\"Il MAE calcolato sul tring set con i migliori parametri è: {improve_mae_tr:.4f}\")\nprint(f\"Il MAE calcolato sul test set con i migliori parametri è: {mae_test:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:21:58.619038Z","iopub.execute_input":"2025-04-24T17:21:58.619381Z","iopub.status.idle":"2025-04-24T17:21:58.625674Z","shell.execute_reply.started":"2025-04-24T17:21:58.619356Z","shell.execute_reply":"2025-04-24T17:21:58.624561Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    if hyperparams['use_pca']:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"],"ename":"IndentationError","evalue":"unindent does not match any outer indentation level (<tokenize>, line 10)","output_type":"error"}],"execution_count":12},{"cell_type":"markdown","source":"In `configuration` avete una lista di dizionari, ogni dizionario contiene una possibile combinazione di hyperparametri da utilizzare nella fase di tring. ","metadata":{}}]}